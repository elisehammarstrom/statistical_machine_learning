{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15098ade-a051-450b-845b-78a6fb4ac922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports only\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.discriminant_analysis as skl_da\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, balanced_accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f604df-856c-4744-991c-ce344989af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'siren_data_train.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26447745-cb01-467f-9aec-a7d0895cdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add distance to horn\n",
    "# Calculate Euclidean distance between person and nearest horn\n",
    "data['dist'] = np.sqrt((data['xcoor'] - data['near_x'])**2 + (data['ycoor'] - data['near_y'])**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e634e22b-2d86-45aa-8e5d-cbc723550924",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"near_fid\"], axis=1) #drop near_fid as it doesnt make sense to have (is only an ID)\n",
    "semi_original_data = data.copy() #make copy to be able to use later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2cb71b-cefd-476e-9e66-9d56b7f79929",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853b278-6b2e-493f-857f-a3bfcd6491b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlations between attributes\n",
    "#from pandas.plotting import scatter_matrix\n",
    "\n",
    "#attributes = data.columns\n",
    "#scatter_matrix(data[attributes], figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495a8fb-7370-4026-9226-2455c6311278",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b75ae6-b09d-45a1-9700-ffdee3cf8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "\n",
    "\n",
    "data['dist_log'] = np.log(data['dist']) #not doing this gives really strange boxplots where the boxes are hard to see\n",
    "data\n",
    "\n",
    "log_dist_heard = df[df['heard'] == 1]['dist_log']\n",
    "log_dist_not_heard = df[df['heard'] == 0]['dist_log']\n",
    "\n",
    "\n",
    "all_distances = [log_dist_heard, log_dist_not_heard]\n",
    "\n",
    "plt.boxplot(all_distances, labels=['Heard', 'Not Heard'], showfliers=False)\n",
    "plt.title('Boxplot of Distances for Heard and Not Heard Instances')\n",
    "plt.xlabel('Heard or Not Heard')\n",
    "plt.ylabel('Logarithmic distance to Horn')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31af0fa-8ac3-4996-bb79-ed7b717ae3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor = 0.001  #scaling the distance as some distances are huge\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(data[\"xcoor\"], data[\"ycoor\"], alpha=0.5, \n",
    "                      c=data[\"heard\"], cmap='RdYlGn', label=\"Heard Siren\",\n",
    "                      s=data[\"dist\"] * scaling_factor, marker='o')\n",
    "plt.colorbar(scatter, label='Heard Siren (1 for heard, 0 for not heard)')\n",
    "plt.xlabel('x-coordinate')\n",
    "plt.ylabel('y-coordinate')\n",
    "plt.title('Scatter Plot of Persons Locations with Distances to Horn')\n",
    "plt.legend()\n",
    "\n",
    "plt.text(0.5, -0.1, \"Size of data point represents distance to horn\", horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e2c0df-a96f-4883-b5ce-7f403b0ff33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Generate synthetic data following a Gaussian distribution for heard and not heard distances\n",
    "mu_heard = np.mean(dist_heard)  # Mean of the distribution for heard distances\n",
    "sigma_heard = np.std(dist_heard)  # Standard deviation of the distribution for heard distances\n",
    "num_samples_heard = len(dist_heard)  # Number of samples for heard distances\n",
    "\n",
    "mu_not_heard = np.mean(dist_not_heard)  # Mean of the distribution for not heard distances\n",
    "sigma_not_heard = np.std(dist_not_heard)  # Standard deviation of the distribution for not heard distances\n",
    "num_samples_not_heard = len(dist_not_heard)  # Number of samples for not heard distances\n",
    "\n",
    "# Generate synthetic data for heard distances\n",
    "distances_heard = np.random.normal(mu_heard, sigma_heard, num_samples_heard)\n",
    "\n",
    "# Generate synthetic data for not heard distances\n",
    "distances_not_heard = np.random.normal(mu_not_heard, sigma_not_heard, num_samples_not_heard)\n",
    "\n",
    "# Plot the histograms for heard and not heard distances\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for heard distances\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(distances_heard, bins=20, density=True, alpha=0.5, color='green', label='Heard')\n",
    "\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu_heard, sigma_heard)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "plt.xlabel('Distance to Horn')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Histogram of Distances where Siren was Heard')\n",
    "plt.legend()\n",
    "\n",
    "# Plot for not heard distances\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(distances_not_heard, bins=20, density=True, alpha=0.5, color='red', label='Not Heard')\n",
    "\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu_not_heard, sigma_not_heard)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "plt.xlabel('Distance to Horn')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Histogram of Distances where Siren was Not Heard')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6174d-8847-46a5-826b-d964c854603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'dist' represents distance and 'heard' represents whether the siren was heard (1 for heard, 0 for not heard)\n",
    "\n",
    "# Plotting the relationship between distance and likelihood of hearing the siren\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='dist', y='heard', data=data, alpha=0.5)\n",
    "\n",
    "# Fitting a trend line (e.g., linear regression) to visualize the relationship\n",
    "sns.regplot(x='dist', y='heard', data=data, scatter=False, color='red')\n",
    "\n",
    "plt.xlabel('Distance to Horn')\n",
    "plt.ylabel('Heard Siren (1 for heard, 0 for not heard)')\n",
    "plt.title('Relationship between Distance to Horn and Likelihood of Hearing Siren')\n",
    "\n",
    "# Set y-axis limits from -3 to 3\n",
    "plt.ylim(-5, 5)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aad552-61bf-42a2-aa79-84bd5abc9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Is there a statistical difference between those that heard the signal and those that didn't given the distance?\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "heard_distances = data[data['heard'] == 1]['dist']\n",
    "not_heard_distances = data[data['heard'] == 0]['dist']\n",
    "\n",
    "# Perform independent two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(heard_distances, not_heard_distances)\n",
    "\n",
    "# Print results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis: There is a significant difference in mean distances between the heard and not heard groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: There is no significant difference in mean distances between the heard and not heard groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a571b3-c69b-48f2-9b5e-39dda0139678",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0ddc9-2f8a-49c3-95f4-e8a75eecf615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "\n",
    "age_heard = df[df['heard'] == 1]['age']\n",
    "age_not_heard = df[df['heard'] == 0]['age']\n",
    "\n",
    "all_ages = [age_heard, age_not_heard]\n",
    "\n",
    "plt.boxplot(all_ages, labels=['Heard', 'Not Heard'])\n",
    "plt.title('Boxplot of Ages for Heard and Not Heard Instances')\n",
    "plt.xlabel('Heard or Not Heard')\n",
    "plt.ylabel('Age')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1aef4e-ee9d-4273-a10f-4688a4a6e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "heard_distances = data[data['heard'] == 1]['age']\n",
    "not_heard_distances = data[data['heard'] == 0]['age']\n",
    "\n",
    "# Perform independent two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(heard_distances, not_heard_distances)\n",
    "\n",
    "# Print results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis: There is a significant difference in mean ages between the heard and not heard groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: There is no significant difference in mean ages between the heard and not heard groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56854354-e47a-41cb-a12a-97f794f4978b",
   "metadata": {},
   "source": [
    "### Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8aa83-ec58-42bb-bb2c-376886716f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data for instances where the siren was heard and not heard\n",
    "angles_heard = data[data['heard'] == 1]['near_angle']\n",
    "angles_not_heard = data[data['heard'] == 0]['near_angle']\n",
    "\n",
    "# Creating a circular histogram for the angles\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plotting histogram for instances where siren was heard\n",
    "plt.hist(angles_heard, bins=36, density=True, alpha=0.5, color='green', label='Heard')\n",
    "\n",
    "# Plotting histogram for instances where siren was not heard\n",
    "plt.hist(angles_not_heard, bins=36, density=True, alpha=0.5, color='red', label='Not Heard')\n",
    "\n",
    "plt.title('Circular Histogram of Angle vs. Heard/Not Heard Siren')\n",
    "plt.xlabel('Angle (degrees)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Setting polar coordinates\n",
    "#plt.gca().set_theta_zero_location('N')\n",
    "#plt.gca().set_theta_direction(-1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686aedf9-dc8c-4ed4-9e7d-c7f8a5750dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'near_angle' represents the angle data and 'heard' represents whether the siren was heard (1 for heard, 0 for not heard)\n",
    "\n",
    "# Separate angles for instances where the siren was heard and not heard\n",
    "angles_heard = data[data['heard'] == 1]['near_angle']\n",
    "angles_not_heard = data[data['heard'] == 0]['near_angle']\n",
    "\n",
    "# Create a polar plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# Plot angles where the siren was heard\n",
    "ax.hist(np.radians(angles_heard), bins=36, density=True, alpha=0.5, color='green', label='Heard')\n",
    "\n",
    "# Plot angles where the siren was not heard\n",
    "ax.hist(np.radians(angles_not_heard), bins=36, density=True, alpha=0.5, color='red', label='Not Heard')\n",
    "\n",
    "# Set the direction of the polar plot as clockwise\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "plt.title('Circular Histogram of Angle vs. Heard/Not Heard Siren')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633a638-baf5-4416-ab13-15cdc606884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'near_angle' represents the angle data, 'heard' represents whether the siren was heard (1 for heard, 0 for not heard),\n",
    "# and 'dist' represents the distance to the horn\n",
    "\n",
    "# Separate angles and distances for instances where the siren was heard and not heard\n",
    "angles_heard = data[data['heard'] == 1]['near_angle']\n",
    "angles_not_heard = data[data['heard'] == 0]['near_angle']\n",
    "\n",
    "distances_heard = data[data['heard'] == 1]['dist']\n",
    "distances_not_heard = data[data['heard'] == 0]['dist']\n",
    "\n",
    "# Create a polar plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# Plot angles where the siren was heard\n",
    "ax.scatter(np.radians(angles_heard), distances_heard, alpha=1, color='green', label='Heard')\n",
    "\n",
    "# Plot angles where the siren was not heard\n",
    "ax.scatter(np.radians(angles_not_heard), distances_not_heard, alpha=0.15, color='red', label='Not Heard')\n",
    "\n",
    "# Set the direction of the polar plot as clockwise\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Angle')\n",
    "plt.ylabel('Distance to Horn')\n",
    "plt.title('Distribution of Angles and Distance to Horn by Heard/Not Heard Siren')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c9938a-1f8b-4354-a076-e3d7895abd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from scipy.stats import ttest_ind\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "heard_distances = data[data['heard'] == 1]['near_angle']\n",
    "not_heard_distances = data[data['heard'] == 0]['near_angle']\n",
    "\n",
    "# Perform independent two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(heard_distances, not_heard_distances)\n",
    "\n",
    "# Print results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis: There is a significant difference in mean angles between the heard and not heard groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: There is no significant difference in mean angles between the heard and not heard groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea14bd-7ba3-4f62-9c4e-ca86a6b3298e",
   "metadata": {},
   "source": [
    "# Creating age grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1e3b5-72a5-494d-aea9-f4e6d27763e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new bins based on hearing with age research\n",
    "new_age_bins = [0, 40, 50, 60, 70, float('inf')]\n",
    "new_age_labels = ['0-39', '40-49', '50-59', '60-69', '70+']\n",
    "data['age_group'] = pd.cut(data['age'], bins=new_age_bins, labels=new_age_labels, right=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0a65d-dbfd-4f72-b603-d1bc2f9ad27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(data, columns=[\"age_group\"])\n",
    "keep_these_original_columns_for_plots = data[[\"age_group\"]]\n",
    "data = pd.concat([keep_these_original_columns_for_plots, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca7c3e-9f3e-4624-9816-ad15840dc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec3235-93fe-4987-9a09-d2eec1ec6578",
   "metadata": {},
   "source": [
    "# Generate train & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3614cf3-d06c-40d2-b470-d55ba970055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random sampling\n",
    "def split_train_test(data, test_ratio, random_state): \n",
    "    shuffled_indices = np.random.permutation(len(data)) if random_state is None else np.random.RandomState(random_state).permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "train, test = split_train_test(data, 0.2, random_state=42)\n",
    "\n",
    "#drop categorical values \n",
    "train = train.drop(columns=[\"age_group\"], axis=1)\n",
    "test = test.drop(columns=[\"age_group\"], axis=1)\n",
    "\n",
    "X_train = train.drop(columns=['heard'])\n",
    "y_train = train['heard']\n",
    "\n",
    "# Extract features and target for testing set\n",
    "X_test = test.drop(columns=['heard'])\n",
    "y_test = test['heard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725af0c-f48a-431f-ae3c-91fd9732c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c692a-dc1a-4852-93a0-4f5bd77ec9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f90eda2-bc97-463c-a667-4b2d5f3c93db",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4822247a-7a9e-4f25-9684-819ce47def75",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = []\n",
    "X_train_LDA = X_train.drop(columns=columns_to_remove , axis=1)\n",
    "X_test_LDA = X_test.drop(columns=columns_to_remove , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463454f-3df2-4d61-9a3e-947368a7d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA with SMOTE, standardscaler and gridsearch, this cell is only used to find best params and solver\n",
    "    \n",
    "smote = SMOTE()\n",
    "    \n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_LDA, y_train)\n",
    "    \n",
    "pipeline = make_pipeline(StandardScaler(), skl_da.LinearDiscriminantAnalysis())\n",
    "    \n",
    "# Define hyperparams\n",
    "param_grid = {\n",
    "    'lineardiscriminantanalysis__solver': ['svd', 'lsqr'],  # solver options for LDA\n",
    "}\n",
    "    \n",
    "# grid search with cross-validation\n",
    "grid_search_lda = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='accuracy', error_score='raise')\n",
    "grid_search_lda.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "# best hyperparams\n",
    "print(\"Best hyperparameters:\", grid_search_lda.best_params_)\n",
    "print(\"Best CV accuracy:\", grid_search_lda.best_score_)\n",
    "    \n",
    "# use best model going forward\n",
    "best_lda_model = grid_search_lda.best_estimator_\n",
    "    \n",
    "# predict with best model\n",
    "prediction_lda = best_lda_model.predict(X_test_LDA)\n",
    "    \n",
    "#Results\n",
    "print(\"Confusion matrix: \\n\")\n",
    "print(pd.crosstab(prediction_lda, y_test), \"\\n\")\n",
    "print(f\"Accuracy: {np.mean(prediction_lda == y_test):.4f}\")\n",
    "\n",
    "print(classification_report(y_test, prediction_lda))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae7ba9-e13d-451a-b9c0-193b51b3e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "model_tree = RandomForestClassifier(n_estimators=440, random_state=42) #defining which modell to be used\n",
    "model_tree.fit(X_train, y_train)\n",
    "model_tree_prediction = model_tree.predict(X_test)\n",
    "\n",
    "print(pd.crosstab(model_tree_prediction, y_test))\n",
    "print(f\"acc: {np.mean(model_tree_prediction == y_test)}\")\n",
    "\n",
    "f1 = f1_score(y_test, model_tree_prediction)\n",
    "balanced_acc = balanced_accuracy_score(y_test, model_tree_prediction)\n",
    "\n",
    "# Compute precision and recall\n",
    "precision = precision_score(y_test, model_tree_prediction)\n",
    "recall = recall_score(y_test, model_tree_prediction)\n",
    "\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Balanced Accuracy:\", balanced_acc)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "print(classification_report(y_test, model_tree_prediction, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909889e7-2e65-411d-99b1-c9311f042483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
    "\n",
    "# rescaling with standardscaler\n",
    "scaler = StandardScaler()\n",
    "X_train_rescaled = scaler.fit_transform(X_train)\n",
    "X_test_rescaled = scaler.transform(X_test)\n",
    "\n",
    "# Bagging classifier\n",
    "bag = BaggingClassifier(random_state=42, n_estimators=20)\n",
    "bag.fit(X_train_rescaled, y_train)\n",
    "prediction = bag.predict(X_test_rescaled)\n",
    "\n",
    "accuracy = bag.score(X_test_rescaled, y_test)\n",
    "\n",
    "print(\"--- Bagging ---\")\n",
    "print(classification_report(y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a8914-2673-4942-aea2-a8f4ec86d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting with AdaBoost\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# rescaling with standardscaler\n",
    "scaler = StandardScaler()\n",
    "X_train_rescaled = scaler.fit_transform(X_train)\n",
    "X_test_rescaled = scaler.transform(X_test)\n",
    "\n",
    "#ada_boost = AdaBoostClassifier(random_state=42, n_estimators=100)\n",
    "#ada_boost.fit(X_train_rescaled, Y_train)\n",
    "#Y_predict = ada_boost.predict(X_test_rescaled)\n",
    "\n",
    "#find best params with GridSearch\n",
    "\n",
    "\n",
    "# Define the pipeline with preprocessing steps (e.g., scaling) and the AdaBoostClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Optional: preprocessing step\n",
    "    ('adaboost', AdaBoostClassifier(random_state=42))  # AdaBoostClassifier\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'adaboost__learning_rate': [1, 2, 5, 10, 25]  # Learning rate hyperparameter for AdaBoostClassifier\n",
    "}\n",
    "\n",
    "# Perform Grid Search cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_rescaled, y_train)\n",
    "\n",
    "# Print the best estimator and its hyperparameters\n",
    "print(\"Best Estimator: \", grid_search.best_estimator_)\n",
    "\n",
    "best_estimator = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0d961-68a8-4dab-8457-50c9fe1a558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the pipeline with preprocessing steps (e.g., scaling) and the AdaBoostClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Optional: preprocessing step\n",
    "    ('adaboost', AdaBoostClassifier(random_state=42))  # AdaBoostClassifier\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid including both n_estimators and learning_rate\n",
    "param_grid = {\n",
    "    'adaboost__n_estimators': [50, 100, 200],  # Number of estimators for AdaBoostClassifier\n",
    "    'adaboost__learning_rate': [0.01, 0.1, 1.0, 2, 5, 10, 2]  # Learning rate for AdaBoostClassifier\n",
    "}\n",
    "\n",
    "# Perform Grid Search cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_rescaled, y_train)\n",
    "\n",
    "# Print the best estimator and its hyperparameters\n",
    "print(\"Best Estimator: \", grid_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17cc0b-e1f6-4fff-92e1-9f148e300f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Adaboost classifier\n",
    "best_boost = AdaBoostClassifier(random_state=42, n_estimators=200, learning_rate=0.1)\n",
    "best_boost.fit(X_train_rescaled, y_train)\n",
    "prediction = best_boost.predict(X_test_rescaled)\n",
    "\n",
    "accuracy = best_boost.score(X_test_rescaled, y_test)\n",
    "\n",
    "pred_accuracy_score = accuracy_score(y_test, prediction)\n",
    "report = classification_report(y_test, prediction)\n",
    "\n",
    "print(\"--- Best AdaBoost ---\")\n",
    "print(classification_report(y_test, prediction, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0284975-b097-4969-8a88-b6ad49e16bfd",
   "metadata": {},
   "source": [
    "##  Each model as a method to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a50051-3a8e-4da2-bab3-c96ddf350682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_LDA():\n",
    "    # LDA with SMOTE, standardscaler and gridsearch\n",
    "    smote = SMOTE()\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_LDA, y_train)\n",
    "    \n",
    "    pipeline = make_pipeline(StandardScaler(), skl_da.LinearDiscriminantAnalysis())\n",
    "    \n",
    "    # Define hyperparams\n",
    "    param_grid = {\n",
    "        'lineardiscriminantanalysis__solver': ['svd', 'lsqr'],  # solver options for LDA\n",
    "    }\n",
    "    \n",
    "    # grid search with cross-validation\n",
    "    grid_search_lda = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='accuracy', error_score='raise')\n",
    "    grid_search_lda.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # use best model going forward\n",
    "    best_lda_model = grid_search_lda.best_estimator_\n",
    "    \n",
    "    # predict with best model\n",
    "    prediction_lda = best_lda_model.predict(X_test_LDA)\n",
    "    \n",
    "    #Results\n",
    "    #result = grid_search_lda.best_score_\n",
    "\n",
    "    result_dict = {}\n",
    "    result_dict['accuracy'] = np.mean(prediction_lda == y_test)\n",
    "    result_dict['f1'] = f1_score(y_test, prediction_lda)\n",
    "    result_dict['balanced_accuracy'] = balanced_accuracy_score(y_test, prediction_lda)\n",
    "    result_dict['precision'] = precision_score(y_test, prediction_lda)\n",
    "    result_dict['recall'] = recall_score(y_test, prediction_lda)\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2963ec-1d94-48d9-9201-510959d5d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_forest():\n",
    "    model_tree = RandomForestClassifier(n_estimators=440, random_state=42) #defining which modell to be used\n",
    "    model_tree.fit(X_train, y_train)\n",
    "    model_tree_prediction = model_tree.predict(X_test)\n",
    "    \n",
    "    #Results\n",
    "    result_dict = {}\n",
    "    result_dict['accuracy'] = np.mean(model_tree_prediction == y_test)\n",
    "    result_dict['f1'] = f1_score(y_test, model_tree_prediction)\n",
    "    result_dict['balanced_accuracy'] = balanced_accuracy_score(y_test, model_tree_prediction)\n",
    "    result_dict['precision'] = precision_score(y_test, model_tree_prediction)\n",
    "    result_dict['recall'] = recall_score(y_test, model_tree_prediction)\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629162ba-8f81-47c0-b022-30d7a7f747c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to run all models to get balanced accuracies\n",
    "num_runs = 10\n",
    "lda_accuracy_array = []\n",
    "rf_accuracy_array = []\n",
    "\n",
    "for i in range(10):\n",
    "    result_dict_lda = perform_LDA()\n",
    "    lda_accuracy_array.append(result_dict_lda['accuracy'])\n",
    "    \n",
    "    #lda_accuracy_array.append(perform_LDA())\n",
    "    result_dict_rf = perform_random_forest()\n",
    "    rf_accuracy_array.append(result_dict_rf['accuracy'])\n",
    "\n",
    "print(\"---- LDA ----\") #Blended Accuracy: 0.8852\n",
    "print(f\"Blended Accuracy: {np.mean(lda_accuracy_array):.4f}\")\n",
    "\n",
    "print(\"---- Random Forest ----\") #Blended Accuracy: 0.9282\n",
    "print(f\"Blended Accuracy: {np.mean(rf_accuracy_array):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c5ebd-0a73-4f6d-90a1-2c26729de3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99010a05-0988-49dc-8c23-ee6050353c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
