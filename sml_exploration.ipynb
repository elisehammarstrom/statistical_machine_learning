{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib\n",
    "#!pip install scikit-learn #ensures it's installed in the correct env\n",
    "#pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports only\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import sklearn.preprocessing as skl_pre\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.discriminant_analysis as skl_da\n",
    "import sklearn.neighbors as skl_nb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'siren_data_train.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#Split the binary columns into zeroes and ones and use that going forwards\n",
    "data = pd.get_dummies(data, columns=[\"building\",\"noise\", \"in_vehicle\", \"asleep\",\"no_windows\"])\n",
    "data_copy = data.copy()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features - distance, age group and distance group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create age group"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created new age buckets based on:\n",
    "https://www.nidcd.nih.gov/health/statistics/hearing-loss-increases-with-age\n",
    "\n",
    "\n",
    "![title](hearing_w_age.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#original bins\n",
    "#age_bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "#age_labels = ['0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '90-100']\n",
    "\n",
    "# Create age groups column\n",
    "#data['age_group'] = pd.cut(data['age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "#new bins based on hearing with age\n",
    "new_age_bins = [0, 40, 50, 60, 70, float('inf')]\n",
    "new_age_labels = ['0-39', '40-49', '50-59', '60-69', '70+']\n",
    "\n",
    "# Create age groups column with new bins\n",
    "data['age_group'] = pd.cut(data['age'], bins=new_age_bins, labels=new_age_labels, right=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add distance to horn\n",
    "# Calculate Euclidean distance between person and nearest horn\n",
    "data['dist'] = np.sqrt((data['xcoor'] - data['near_x'])**2 + (data['ycoor'] - data['near_y'])**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create distance group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add distance groups\n",
    "# Create bins for distance ranging from 0 to 3000 with a step size of 100\n",
    "step_size = 500\n",
    "distance_bins = np.arange(0, 3100, step_size)\n",
    "\n",
    "# Create labels for distance bins\n",
    "distance_labels = [f'{i}-{i+step_size}' for i in range(0, 3000, step_size)]\n",
    "# Append a bin edge for values greater than 3000\n",
    "distance_bins = np.append(distance_bins, np.inf)\n",
    "distance_labels.append('>3000')\n",
    "\n",
    "# Assign each distance value to a corresponding bin\n",
    "data['distance_groups'] = pd.cut(data['dist'], bins=distance_bins, labels=distance_labels, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dummies for newly created categorical data but keep original columns for the plots later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(data, columns=[\"age_group\", \"distance_groups\", \"heard\"])\n",
    "\n",
    "keep_these_original_columns_for_plots = data[[\"heard\", \"distance_groups\", \"age_group\"]]\n",
    "\n",
    "data = pd.concat([keep_these_original_columns_for_plots, dummies], axis=1)\n",
    "\n",
    "data_copy = data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random sampling\n",
    "def split_train_test(data, test_ratio): \n",
    "    shuffled_indices = np.random.permutation(len(data)) #creates array of indices that are randomly shuffled\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "#stratified sampling, where we create a sample that takes the distribution of age into account\n",
    "def stratified_sampling(data, test_ratio, important_data_column):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size = test_ratio, random_state=42)\n",
    "    for train_index, test_index in split.split(data, important_data_column):\n",
    "        strat_train_set = data.loc[train_index]\n",
    "        strat_test_set = data.loc[test_index]\n",
    "    return strat_train_set, strat_test_set\n",
    "\n",
    "\n",
    "#create samples\n",
    "train, test = stratified_sampling(data, 0.2, data[\"age\"])\n",
    "#print(len(test_set))\n",
    "#print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare performances, stratified sampling is better for age group\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "def split_comparison(data, target_column, test_size=0.2, random_state=None):\n",
    "    # Original data overall performance\n",
    "    overall_performance = data[target_column].value_counts(normalize=True)\n",
    "    \n",
    "    # Stratified Sampling\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    for train_index, test_index in split.split(data, data[target_column]):\n",
    "        strat_train_set = data.loc[train_index]\n",
    "        strat_test_set = data.loc[test_index]\n",
    "    \n",
    "    # Random Sampling\n",
    "    rand_train_set, rand_test_set = train_test_split(data, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Calculate performance metrics for stratified sampling\n",
    "    strat_train_performance = strat_train_set[target_column].value_counts(normalize=True)\n",
    "    strat_test_performance = strat_test_set[target_column].value_counts(normalize=True)\n",
    "    \n",
    "    # Calculate performance metrics for random sampling\n",
    "    rand_train_performance = rand_train_set[target_column].value_counts(normalize=True)\n",
    "    rand_test_performance = rand_test_set[target_column].value_counts(normalize=True)\n",
    "    \n",
    "    # Calculate percentage error\n",
    "    strat_train_error = ((strat_train_performance - overall_performance) / overall_performance) * 100\n",
    "    strat_test_error = ((strat_test_performance - overall_performance) / overall_performance) * 100\n",
    "    \n",
    "    rand_train_error = ((rand_train_performance - overall_performance) / overall_performance) * 100\n",
    "    rand_test_error = ((rand_test_performance - overall_performance) / overall_performance) * 100\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Overall performance': overall_performance,\n",
    "        'Stratified': strat_test_performance,\n",
    "        'Random': rand_test_performance,\n",
    "        'Strat. % error': strat_test_error,\n",
    "        'Rand. % error': rand_test_error\n",
    "    })\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "# Example usage:\n",
    "comparison_table = split_comparison(data, target_column='age', test_size=0.2, random_state=42)\n",
    "print(comparison_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which features shall we include?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop some columns to easier filter out whats important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data = data.copy().drop(columns=[\"near_fid\", \"near_y\", \"near_x\", \"xcoor\", \"ycoor\"], inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = mini_data.corr()\n",
    "corr_matrix[\"heard_1\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(mini_data.corr());\n",
    "\n",
    "# Increase the size of the heatmap.\n",
    "plt.figure(figsize=(16, 6))\n",
    "# Store heatmap object in a variable to easily access it when you want to include more features (such as title).\n",
    "# Set the range of values to be displayed on the colormap from -1 to 1, and set the annotation to True to display the correlation values on the heatmap.\n",
    "heatmap = sns.heatmap(mini_data.corr(), vmin=-1, vmax=1, annot=False)\n",
    "# Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above heatmap, we can see that these features positively affects heard_1:\n",
    "Being in a building, not having any noise, not being in a vehicle, not being asleet (slight corr), to have windows, and being in the agegroup 0-50 y/o along with being 0-1000 (metres?) away from the horn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set X_train, X_test, y_train and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop categorical values \n",
    "train = train.drop(columns=[\"distance_groups\", \"age_group\"], axis=1)\n",
    "test = test.drop(columns=[\"distance_groups\", \"age_group\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#right now we have all features, pls change\n",
    "\n",
    "X_train = train.drop(columns=['heard', \"heard_0\", \"heard_1\"])\n",
    "y_train = train['heard']\n",
    "\n",
    "# Extract features and target for testing set\n",
    "X_test = test.drop(columns=['heard', \"heard_0\", \"heard_1\"])\n",
    "y_test = test['heard']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (i) Does the distance to the nearest horn affect whether a person hears the siren or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing distance and heard\n",
    "\n",
    "#temp_data = data_copy\n",
    "\n",
    "# Create stacked bar chart\n",
    "pd.crosstab(data['distance_groups'], data['heard']).plot.bar(stacked=True)\n",
    "plt.xlabel('Distance to Horn')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Relationship between Distance to Horn and \"Heard\"')\n",
    "plt.legend(title='Heard')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_num = data.pivot_table(index = ['distance_groups'], columns= 'heard', aggfunc='size')\n",
    "\n",
    "dist_num[1] = dist_num[1].fillna(0)\n",
    "dist_num[0] = dist_num[0].fillna(0)\n",
    "dist_num_1 = np.array(dist_num[1])\n",
    "dist_num_0 = np.array(dist_num[0])\n",
    "\n",
    "dist_procent = (dist_num_1)/(dist_num_1+dist_num_0)*100\n",
    "\n",
    "index_dist = np.array(dist_num.index)\n",
    "\n",
    "\n",
    "plt.plot(index_dist, dist_procent)\n",
    "plt.xlabel('Distance ()')\n",
    "plt.title(\"Distance to horn and % who heard it from that distance\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('The procent hearing (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is there a statistical difference between those that heard the signal and those that didn't given the distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Split data into two groups based on 'heard' column\n",
    "heard_group = data[data['heard'] == 1]['dist']\n",
    "not_heard_group = data[data['heard'] == 0]['dist']\n",
    "\n",
    "\n",
    "# Visualize distributions (optional)\n",
    "# Example: sns.histplot(heard_group, label='Heard')\n",
    "# Example: sns.histplot(not_heard_group, label='Not Heard')\n",
    "# Add legend, labels, and titles as necessary\n",
    "\n",
    "# Perform t-test\n",
    "t_statistic, p_value = stats.ttest_ind(heard_group, not_heard_group)\n",
    "\n",
    "# Interpret results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There is a statistically significant difference in the distributions.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference in the distributions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (ii) Are the people who hear the siren younger than the people who do not hear it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Comparing age and heard\n",
    "\n",
    "# Create stacked bar chart\n",
    "pd.crosstab(data['age_group'], data['heard']).plot.bar(stacked=True)\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Relationship between Age Groups and \"Heard\"')\n",
    "plt.legend(title='Heard')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The relationship between age and hearing\n",
    "age_num = data_copy.pivot_table(index = ['age'], columns= 'heard', aggfunc='size')\n",
    "\n",
    "age_num[1] = age_num[1].fillna(0)\n",
    "age_num[0] = age_num[0].fillna(0)\n",
    "age_num_1 = np.array(age_num[1])\n",
    "age_num_0 = np.array(age_num[0])\n",
    "\n",
    "age_procent = (age_num_1)/(age_num_1+age_num_0)*100 #procent som hör per åldersgrupp\n",
    "\n",
    "index_age = np.array(age_num.index)\n",
    "\n",
    "plt.plot(index_age, age_procent)\n",
    "plt.xlabel('age (years)')\n",
    "plt.ylabel('The procent hearing (%)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (iii) Does the direction towards the nearest horn affect whether a person hears the siren or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create bins for angle ranging from 0 to 2000 with a step size of 100\n",
    "angle_bins = np.arange(0, 181, 12)\n",
    "\n",
    "# Create labels for angle bins\n",
    "angle_labels = [f'{i}-{i+15}' for i in range(0, 180, 12)]\n",
    "\n",
    "# Assign each angle value to a corresponding bin\n",
    "data['ange_span'] = pd.cut(data['near_angle'], bins=angle_bins, labels=angle_labels, right=False)\n",
    "\n",
    "angle_num = data.pivot_table(index = ['ange_span'], columns= 'heard', aggfunc='size')\n",
    "\n",
    "angle_num_1 = np.array(angle_num[1])\n",
    "angle_num_0 = np.array(angle_num[0])\n",
    "\n",
    "angle_procent = (angle_num_1 )/(angle_num_1 +angle_num_0)*100 #procent som hör\n",
    "\n",
    "index_angle = np.array(angle_num.index)\n",
    "\n",
    "plt.plot(index_angle, angle_procent)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('The procent hearing (%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepering the data for training and validation\n",
    "\n",
    "data['dist'] = np.sqrt((data.near_x - data.xcoor)**2 + (data.near_y - data.ycoor)**2)\n",
    "\n",
    "feat = ['near_fid', 'near_x', 'near_y', 'near_angle', 'xcoor', 'ycoor',\n",
    "       'age', 'building_0', 'building_1', 'noise_0', 'noise_1', 'in_vehicle_0',\n",
    "       'in_vehicle_1', 'asleep_0', 'asleep_1', 'no_windows_0', 'no_windows_1', 'dist']\n",
    "\n",
    "x = data[feat] #inputs\n",
    "\n",
    "y = data.heard # output\n",
    "\n",
    "x = data[feat] #inputs\n",
    "\n",
    "y = data['heard'] # output \n",
    "train_X, val_X, train_y, val_y = train_test_split(x,y, random_state=0, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = RandomForestClassifier()\n",
    "\n",
    "par = {'n_estimators': stats.randint(50, 750), 'criterion':['gini', 'entropy'], 'max_depth': [4, 5, 6, 7, 8, 9], 'min_samples_split' : [1,2,3,4, 5, 6]}\n",
    "\n",
    "\n",
    "RSC = RandomizedSearchCV(model_tree, param_distributions = par, n_iter = 10, cv=5, n_jobs = -1 )\n",
    "\n",
    "RSC.fit(train_X, train_y)\n",
    "\n",
    "model_tree = RSC.best_estimator_\n",
    "\n",
    "model_tree.fit(train_X, train_y)\n",
    "\n",
    "model_tree_prediction = model_tree.predict(val_X)\n",
    "\n",
    "print(pd.crosstab(model_tree_prediction, val_y))\n",
    "print(f\"acc: {np.mean(model_tree_prediction == val_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.crosstab(model_tree_prediction, val_y))\n",
    "print(f\"acc: {np.mean(model_tree_prediction == val_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA and QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.discriminant_analysis as skl_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = skl_da.LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_lda = lda_model.predict_proba(X_test)\n",
    "\n",
    "print(\"The class order in the model: \")\n",
    "print(lda_model.classes_)\n",
    "\n",
    "print(\"Examples of predicted probabilities for the above classes: \")\n",
    "with np.printoptions(suppress=True, precision=6):\n",
    "    print(predict_prob_lda[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lda = np.empty(len(X_test), dtype=object)\n",
    "prediction_lda = np.where(predict_prob_lda[:, 0] >= 0.5, 0, 1) #0 is not heard, 1 is heard\n",
    "print(\"Five first predictions: \")\n",
    "print(prediction_lda[0:5], \"\\n\")\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion matrix: \\n\")\n",
    "print(pd.crosstab(prediction_lda, y_test), \"\\n\")\n",
    "\n",
    "#Accuracy\n",
    "print(f\"Accuracy: {np.mean(prediction_lda == y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_model = skl_da.QuadraticDiscriminantAnalysis()\n",
    "qda_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we get this warning above, we need to determine which variables correlate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Check which features correlate pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimizing pairwise correlating features \n",
    "in_vehicle_0  correlates with noise_0 and same for opposite --> choose only noise\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose either one of these \"groups\" to activate different combinations of features\n",
    "#with removal of features that pairwise correlate with another feature\n",
    "\n",
    "#using this set gives accuracy of 74%.... in comparison, using all features gives accuracy 90%\n",
    "#X_train_mini = X_train.drop(columns=[\"xcoor\", \"ycoor\", \"near_x\", \"near_y\", \"near_angle\", \"dist\", \"age\"], axis=1)\n",
    "#X_test_mini = X_test.drop(columns=[\"xcoor\", \"ycoor\", \"near_x\", \"near_y\", \"near_angle\", \"dist\", \"age\"], axis=1)\n",
    "\n",
    "#all features\n",
    "X_train_mini = X_train\n",
    "X_test_mini = X_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the correlation matrix\n",
    "corr_matrix = X_train_mini.corr()\n",
    "\n",
    "# Plotting the correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_model = skl_da.QuadraticDiscriminantAnalysis()\n",
    "qda_model.fit(X_train_mini, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  add this info to the report: https://stats.stackexchange.com/questions/29385/collinear-variables-in-multiclass-lda-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### As many values correlate together, one idea is to group them going forward. \n",
    "# Otherwise we likely get weird results below. But for now I will let it be, fix laterrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_qda = qda_model.predict_proba(X_test_mini)\n",
    "\n",
    "print(\"The class order in the model: \")\n",
    "print(qda_model.classes_)\n",
    "\n",
    "print(\"Examples of predicted probabilities for the above classes: \")\n",
    "with np.printoptions(suppress=True, precision=6):\n",
    "    print(predict_prob_qda[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_qda = np.empty(len(X_test), dtype=object)\n",
    "prediction_qda = np.where(predict_prob_qda[:, 0] >= 0.5, 0, 1) #0 is not heard, 1 is heard\n",
    "print(\"Five first predictions: \")\n",
    "print(prediction_qda[0:5], \"\\n\")\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion matrix: \\n\")\n",
    "print(pd.crosstab(prediction_qda, y_test), \"\\n\")\n",
    "\n",
    "#Accuracy\n",
    "print(f\"Accuracy: {np.mean(prediction_qda == y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is from another course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_interval(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    labels=None,\n",
    "    alpha = 0.01,\n",
    "    union_bound_correction=True\n",
    "):\n",
    "    \"\"\"Produces a classification report with precision, recall and accuracy\n",
    "    It also uses Hoeffdings inequality to produce confidence intervals around\n",
    "    each measurement. We can do this with or without multiple measurement\n",
    "    correction (union bound correction).\n",
    "\n",
    "    Example output is:\n",
    "                labels           precision             recall\n",
    "\n",
    "               0.0  0.88 : [0.50,1.00] 0.40 : [0.15,0.65]\n",
    "               1.0  0.56 : [0.34,0.78] 0.93 : [0.65,1.00]\n",
    "\n",
    "          accuracy                                        0.64 : [0.45,0.83]\n",
    "\n",
    "    Parameters:\n",
    "    y_true                          -- The true labels\n",
    "    y_pred                          -- The predicted labels\n",
    "    labels                          -- TODO\n",
    "    alpha[0.01]                     -- The confidence level of the intervals\n",
    "    union_bound_correction[True]    -- If we should compensate with the union bound because we\n",
    "                                    have multiple intervals to compute in order to keep the level\n",
    "                                    of confidence for all intervals jointly.\n",
    "\n",
    "    Returns:\n",
    "    a printable string.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    def precision_recall(y_true,\n",
    "        y_pred,\n",
    "        labels=None,alpha=0.01, correction=1):\n",
    "        p = []\n",
    "        r = []\n",
    "        f1 = []\n",
    "        support = []\n",
    "        for label in labels:\n",
    "            y_true_pred_label = y_true[y_pred == label]\n",
    "            precision = np.mean(y_true_pred_label == label)\n",
    "            delta = (1/np.sqrt(len(y_true_pred_label)))*np.sqrt((1/2)*np.log(2*correction/alpha))\n",
    "            p.append(\"%.2f : [%.2f,%.2f]\" % (precision, np.maximum(precision-delta,0),np.minimum(precision+delta,1)))\n",
    "\n",
    "            y_pred_true_label = y_pred[y_true == label]\n",
    "            recall = np.mean(y_pred_true_label == label)\n",
    "            delta = (1/np.sqrt(len(y_pred_true_label)))*np.sqrt((1/2)*np.log(2*correction/alpha))\n",
    "            r.append(\"%.2f : [%.2f,%.2f]\" % (recall, np.maximum(recall-delta,0),np.minimum(recall+delta,1)))\n",
    "\n",
    "        return (p,r)\n",
    "\n",
    "    def accuracy_interval(y_true,y_pred,alpha=0.01,correction=1):\n",
    "        acc = np.mean(y_true == y_pred)\n",
    "        delta = (1/np.sqrt(len(y_true)))*np.sqrt((1/2)*np.log(2*correction/alpha))\n",
    "        return \"%.2f : [%.2f,%.2f]\" % (acc, np.maximum(acc-delta,0),np.minimum(acc+delta,1))\n",
    "\n",
    "    digits = 18\n",
    "    target_names = None\n",
    "    if labels is None:\n",
    "        labels = list(set(y_true).union(set(y_pred)))\n",
    "        labels_given = False\n",
    "    else:\n",
    "        labels = np.asarray(labels)\n",
    "        labels_given = True\n",
    "\n",
    "    target_names = [\"%s\" % l for l in labels]\n",
    "\n",
    "    headers = [\"precision\", \"recall\"]\n",
    "    # compute per-class results without averaging\n",
    "    # Simple correction using the union bound\n",
    "    # We are computing 2 intervals for each label for precision and recall\n",
    "    # In addition we are computing 2 intervals for accuracy\n",
    "    # This is in total 2*n_labels+2\n",
    "    if (union_bound_correction):\n",
    "        correction = 2*len(labels)+2\n",
    "    else:\n",
    "        correction=1\n",
    "    p, r = precision_recall(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=labels,\n",
    "        alpha=alpha,\n",
    "        correction=correction\n",
    "    )\n",
    "\n",
    "    rows = zip(target_names, p, r)\n",
    "\n",
    "    name_width = max(len(cn) for cn in target_names)\n",
    "    width = max(name_width, digits)\n",
    "    head_fmt = \"{:>{width}s} \" + \" {:>{digits}}\" * len(headers)\n",
    "    report = head_fmt.format(\"labels\", *headers, width=width,digits=digits)\n",
    "    report += \"\\n\\n\"\n",
    "    row_fmt = \"{:>{width}s} \" + \" {:>{digits}s}\" * 2 + \"\\n\"\n",
    "    for row in rows:\n",
    "        report += row_fmt.format(*row, width=width, digits=digits)\n",
    "    row_fmt_acc = \"{:>{width}s} \" + \" {:>{digits}s}\" * 2 + \" {:>{digits}s}\"\"\\n\"\n",
    "    report += \"\\n\"\n",
    "    accuracy = accuracy_interval(y_true,y_pred,alpha=alpha,correction=correction)\n",
    "    report+=row_fmt_acc.format(*(\"accuracy\",\"\",\"\",accuracy),width=width,digits=digits)\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_lda = classification_report_interval(\n",
    "    y_test.values.reshape(-1),\n",
    "    prediction_lda,\n",
    "    alpha = 0.05,\n",
    ")\n",
    "\n",
    "print(\"Performance assessment LDA\")\n",
    "print(\"Confidence intervals are within brackets\")\n",
    "print(report_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_qda = classification_report_interval(\n",
    "    y_test.values.reshape(-1),\n",
    "    prediction_qda,\n",
    "    alpha = 0.05,\n",
    ")\n",
    "\n",
    "print(\"Performance assessment QDA\")\n",
    "print(\"Confidence intervals are within brackets\")\n",
    "print(report_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
